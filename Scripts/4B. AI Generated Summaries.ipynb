{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea60439-99e8-4019-9ad7-4a39dc6136a1",
   "metadata": {},
   "source": [
    "## 4B. AI Generated Summaries for Dashboard\n",
    "\n",
    "Last Updated: 6 Oct 2025 </br>\n",
    "Description: Gemini AI was utilised to generate AI summaries and actionable insights from the top 20 positive and negative reviews for each aspect based on relevance score and sentiment score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13234b19-1a82-4765-91f5-a4f9108cfbaf",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a082e0a8-9b3b-4735-a4c6-a5c43e281616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dddfd5c-5bce-4888-8381-84aa61013fc8",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7182e1fa-cdec-4b28-809e-50778961ccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI (Gemini) authenticated successfully using JSON credentials.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1. Set the path to your JSON credentials file.\n",
    "    CREDENTIALS_FILE = \"credentials/causal-cacao-473308-d4-f7b956a7b6e8.json\"\n",
    "    \n",
    "    # 2. Set your Google Cloud Project ID.\n",
    "    PROJECT_ID = \"causal-cacao-473308-d4\" # Replace with your project ID\n",
    "    \n",
    "    # 3. Set the location of your project (e.g., \"us-central1\").\n",
    "    LOCATION = \"us-central1\" # Replace with your project's region\n",
    "\n",
    "    # Set the credentials environment variable for the session\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = CREDENTIALS_FILE\n",
    "    \n",
    "    # Initialize the Vertex AI SDK\n",
    "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "    \n",
    "    print(\"Vertex AI (Gemini) authenticated successfully using JSON credentials.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Vertex AI: {e}\")\n",
    "    print(\"Please ensure your Project ID, Location, and credentials file path are correct.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435f7a14-ed6b-4f89-8cb7-17e5643c7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model name to use\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "# Define input/output file paths\n",
    "INPUT_FILE = \"../Output/absa_analysis_twostep_results_wide.csv\"\n",
    "OUTPUT_FILE = \"../Output/gemini_actionable_insights.csv\"\n",
    "\n",
    "# The list of aspects you want to analyze\n",
    "ASPECTS = [\n",
    "    \"Room Quality & Comfort\", \"Facilities & Amenities\", \"Customer Service & Staff\",\n",
    "    \"Dining Experience\", \"Casino Experience\", \"Shopping & Retail\",\n",
    "    \"Location & Accessibility\", \"Pricing & Value for Money\", \"Atmosphere & Ambience\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5784b-2856-4108-8722-3eb3a3cabb7d",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d59a7b07-1c15-4e07-bc6e-443c070c2986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_retry(prompt, model_name=MODEL_NAME, retries=3, delay=5):\n",
    "    \"\"\"\n",
    "    Calls the Vertex AI Gemini API with a retry mechanism.\n",
    "    \"\"\"\n",
    "    model = GenerativeModel(model_name)\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            # Generate content using the Vertex AI method\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"API call failed (attempt {i+1}/{retries}): {e}\")\n",
    "            if i < retries - 1:\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2 # Exponential backoff\n",
    "            else:\n",
    "                print(\"Max retries reached. Returning error.\")\n",
    "                return f\"ERROR: API call failed after {retries} retries.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a209b468-d20f-4c0f-ad16-3655837f70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aspect_summary(aspect, reviews, sentiment_type):\n",
    "    \"\"\"\n",
    "    Builds a detailed prompt, calls the Gemini API, and parses the response\n",
    "    to extract themes and actionable recommendations.\n",
    "    \"\"\"\n",
    "    reviews_text = \"\\n\".join([f\"- {review}\" for review in reviews])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        ### ROLE:\n",
    "        You are a world-class hospitality management consultant analyzing {sentiment_type} feedback for the Marina Bay Sands hotel. Your analysis must be sharp, concise, and focused on operational improvements.\n",
    "        \n",
    "        ### TASK:\n",
    "        Analyze the following guest reviews which are specifically about the aspect of **\"{aspect}\"**. Based ONLY on this feedback, identify the top 3 recurring themes and provide specific, actionable recommendations for hotel management.\n",
    "        \n",
    "        ### REVIEWS TO ANALYZE:\n",
    "        {reviews_text}\n",
    "        \n",
    "        ### REQUIRED OUTPUT FORMAT:\n",
    "        Your response MUST strictly follow this format, using these exact tags:\n",
    "        <ANALYSIS>\n",
    "        1. **[Theme 1]:** [Briefly describe the first major theme found in the reviews.]\n",
    "        2. **[Theme 2]:** [Briefly describe the second major theme.]\n",
    "        3. **[Theme 3]:** [Briefly describe the third major theme.]\n",
    "        </ANALYSIS>\n",
    "        <ACTION_PLAN>\n",
    "        1. **[Action 1]:** [Provide a specific, operational action item that addresses one of the themes.]\n",
    "        2. **[Action 2]:** [Provide another specific, operational action item.]\n",
    "        3. **[Action 3]:** [Provide a third specific, operational action item.]\n",
    "        </ACTION_PLAN>\n",
    "        \"\"\"\n",
    "    \n",
    "    response_text = generate_with_retry(prompt)\n",
    "    \n",
    "    try:\n",
    "        analysis = response_text.split(\"<ANALYSIS>\")[1].split(\"</ANALYSIS>\")[0].strip()\n",
    "        action_plan = response_text.split(\"<ACTION_PLAN>\")[1].split(\"</ACTION_PLAN>\")[0].strip()\n",
    "    except IndexError:\n",
    "        print(f\"  - Warning: Could not parse response for {aspect} ({sentiment_type}). Returning raw response.\")\n",
    "        analysis = f\"Parsing Error. Raw Response: {response_text[:500]}...\"\n",
    "        action_plan = \"Parsing Error.\"\n",
    "        \n",
    "    return analysis, action_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e64efb-c1cc-4697-aab0-37605aaf9d11",
   "metadata": {},
   "source": [
    "#### Script Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49780b1f-e89a-42b4-8506-d7332d90265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data from output/absa_analysis_twostep_results_wide.csv...\n",
      "Data loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Pausing for 10 seconds to respect API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects:  11%|█         | 1/9 [00:23<03:04, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Pausing for 10 seconds to respect API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects:  22%|██▏       | 2/9 [00:39<02:13, 19.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Pausing for 10 seconds to respect API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects:  33%|███▎      | 3/9 [00:55<01:46, 17.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Pausing for 10 seconds to respect API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects:  44%|████▍     | 4/9 [01:11<01:25, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Pausing for 10 seconds to respect API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects:  56%|█████▌    | 5/9 [01:28<01:07, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Pausing for 10 seconds to respect API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects:  67%|██████▋   | 6/9 [01:44<00:49, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Pausing for 10 seconds to respect API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects:  78%|███████▊  | 7/9 [02:00<00:32, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Pausing for 10 seconds to respect API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects:  89%|████████▉ | 8/9 [02:15<00:16, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Pausing for 10 seconds to respect API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Insights for Aspects: 100%|██████████| 9/9 [02:32<00:00, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "INSIGHTS GENERATION COMPLETE\n",
      "==================================================\n",
      "\n",
      "Final results have been saved to: output/gemini_actionable_insights.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(f\"\\nLoading data from {INPUT_FILE}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_FILE)\n",
    "        print(\"Data loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Input file not found at '{INPUT_FILE}'\")\n",
    "        print(\"Please make sure you have run the ABSA script first to generate this file.\")\n",
    "        exit()\n",
    "\n",
    "    results_list = []\n",
    "    \n",
    "    for aspect in tqdm(ASPECTS, desc=\"Generating Insights for Aspects\"):\n",
    "        \n",
    "        sentiment_col = f\"{aspect}_sentiment\"\n",
    "        relevance_col = f\"{aspect}_relevance_score\"\n",
    "        sentiment_score_col = f\"{aspect}_sentiment_score\"\n",
    "\n",
    "        # --- Process POSITIVE Reviews ---\n",
    "        top_positive_reviews = df[df[sentiment_col] == 'Positive'].sort_values(\n",
    "            by=[relevance_col, sentiment_score_col], ascending=False\n",
    "        ).head(20)['review_text'].tolist()\n",
    "\n",
    "        positive_analysis, positive_action = \"\", \"\"\n",
    "        if top_positive_reviews:\n",
    "            positive_analysis, positive_action = generate_aspect_summary(aspect, top_positive_reviews, \"Positive\")\n",
    "        \n",
    "        # --- Process NEGATIVE Reviews ---\n",
    "        top_negative_reviews = df[df[sentiment_col] == 'Negative'].sort_values(\n",
    "            by=[relevance_col, sentiment_score_col], ascending=False\n",
    "        ).head(20)['review_text'].tolist()\n",
    "        \n",
    "        negative_analysis, negative_action = \"\", \"\"\n",
    "        if top_negative_reviews:\n",
    "            negative_analysis, negative_action = generate_aspect_summary(aspect, top_negative_reviews, \"Negative\")\n",
    "\n",
    "        results_list.append({\n",
    "            \"aspect\": aspect,\n",
    "            \"positive_sentiments_analysis\": positive_analysis,\n",
    "            \"positive_sentiments_action\": positive_action,\n",
    "            \"negative_sentiments_analysis\": negative_analysis,\n",
    "            \"negative_sentiments_action\": negative_action\n",
    "        })\n",
    "\n",
    "        # --- Add a delay to avoid hitting API rate limits ---\n",
    "        # A 10-second pause between each aspect (which makes 2 API calls) is a safe buffer.\n",
    "        print(f\"  - Pausing for 10 seconds to respect API rate limits...\")\n",
    "        time.sleep(10)\n",
    "\n",
    "    final_insights_df = pd.DataFrame(results_list)\n",
    "\n",
    "    # --- SAVE THE FINAL RESULTS ---\n",
    "    if not os.path.exists(\"output\"):\n",
    "        os.makedirs(\"output\")\n",
    "        \n",
    "    final_insights_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"INSIGHTS GENERATION COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nFinal results have been saved to: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af26f4-9e3d-4500-95f1-89f1f703cdea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
