{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1cc19c-329c-4b64-9406-b4406c5457fc",
   "metadata": {
    "id": "bb1cc19c-329c-4b64-9406-b4406c5457fc"
   },
   "source": [
    "## 4A. Aspect Based Sentiment Analysis (ABSA)\n",
    "\n",
    "Last Updated: 4 Oct 2025 </br>\n",
    "Description: One-step and Two-step ABSA Pipeline was experimented. Two Step Pipeline for Sentiment Analysis was eventually adopted for greater aspect relevance and accurate sentiment analysis results. Note that this script was ran using Google Collab to leverage on the T4 GPU for efficient processing. In addition, we will be using the cleaned_reviews_polars.csv dataset since we will only be using the raw text from \"review_text\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M1CtoW_K564w",
   "metadata": {
    "id": "M1CtoW_K564w"
   },
   "source": [
    "#### Mount Drive for T4 GPU on Google Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "I78-mIF154r6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18416,
     "status": "ok",
     "timestamp": 1759644582478,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "I78-mIF154r6",
    "outputId": "028825b5-ca3e-405b-a3ef-b43804fef9ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd85015-161e-457d-9c27-b2c37b928f20",
   "metadata": {
    "id": "6fd85015-161e-457d-9c27-b2c37b928f20"
   },
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b87bfa96-c568-4e6e-8113-7cab6bdce759",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1759644582495,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "b87bfa96-c568-4e6e-8113-7cab6bdce759"
   },
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d78ade6-c3d2-467c-a65c-5bea53d26e50",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1759644582497,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "2d78ade6-c3d2-467c-a65c-5bea53d26e50"
   },
   "outputs": [],
   "source": [
    "# pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c341420a-6d1b-440c-bbba-3361dc552a0d",
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1759645087540,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "c341420a-6d1b-440c-bbba-3361dc552a0d"
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Ignore warnings that are cluttering the output\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning) # Add this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ntVIO2l1-591",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759644891088,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "ntVIO2l1-591",
    "outputId": "c0f8c666-4dce-4aac-a810-35e841327b78"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6055c55-fd43-40f0-adc0-340bd5a675ac",
   "metadata": {
    "id": "e6055c55-fd43-40f0-adc0-340bd5a675ac"
   },
   "source": [
    "#### File Path Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fed75813-4a1b-4d9b-b753-521dc8abab7f",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759645091468,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "fed75813-4a1b-4d9b-b753-521dc8abab7f"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATA_DIR = \"data/\"\n",
    "\n",
    "FILE_PATH = \"/content/drive/MyDrive/CI/data/cleaned_reviews_polars.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd976095-cbd0-45c9-9da2-af7292d06889",
   "metadata": {
    "id": "bd976095-cbd0-45c9-9da2-af7292d06889"
   },
   "source": [
    "#### Aspect Definition\n",
    "\n",
    "- The aspects for this analysis were defined using a deductive, top-down methodology to ensure relevance and comprehensive coverage of the guest experience.\n",
    "- Nine distinct categories were predefined based on a three-pronged rationale:\n",
    "1) Industry-Standard Criteria, mirroring common review categories found on major travel platforms (e.g., 'Location & Accessibility', 'Pricing & Value for Money')\n",
    "2) Domain-Specific Features, identifying unique attributes of the Marina Bay Sands (e.g., 'Casino Experience', 'Shopping & Retail')\n",
    "3) General Service Aspects, covering universal elements of hospitality (e.g., 'Room Quality & Comfort', 'Customer Service & Staff').\n",
    "\n",
    "This structured approach ensures that the subsequent sentiment analysis is grounded in categories that are both widely understood and directly pertinent to MBS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9efd83f9-e19a-4fb0-8cb4-2d47e73b20c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1759645095537,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "9efd83f9-e19a-4fb0-8cb4-2d47e73b20c0"
   },
   "outputs": [],
   "source": [
    "ASPECTS = [\n",
    "    \"Room Quality & Comfort\",\n",
    "    \"Facilities & Amenities\",\n",
    "    \"Customer Service & Staff\",\n",
    "    \"Dining Experience\",\n",
    "    \"Casino Experience\",\n",
    "    \"Shopping & Retail\",\n",
    "    \"Location & Accessibility\",\n",
    "    \"Pricing & Value for Money\",\n",
    "    \"Atmosphere & Ambience\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc93d7-5db5-45f0-b450-5eca72791f9c",
   "metadata": {
    "id": "b0fc93d7-5db5-45f0-b450-5eca72791f9c"
   },
   "source": [
    "#### Load Data\n",
    "- Note that natively got review_id already in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e75d23-136a-463e-b8ed-86d03c83509a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1759644524149,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "29e75d23-136a-463e-b8ed-86d03c83509a",
    "outputId": "46e32831-0915-4b9c-9846-f02406894808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned dataset...\n",
      "Error loading dataset: name 'pl' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Not required for two step pipeline\n",
    "\n",
    "print(\"Loading cleaned dataset...\")\n",
    "# Load the cleaned dataset produced by your Polars pipeline\n",
    "try:\n",
    "    df = pl.read_csv(\"data/imputed_reviews_polars.csv\")\n",
    "    # Add a unique ID to each review for easier joining later\n",
    "    df = df.with_row_index(name=\"review_id\")\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bc2ed-d17f-4d7e-912a-ccb40fe10348",
   "metadata": {
    "id": "0a3bc2ed-d17f-4d7e-912a-ccb40fe10348"
   },
   "source": [
    "#### Exclude Reviews with low word count\n",
    "- To improve the quality of the dataset, reviews containing five or fewer words were excluded, as these entries typically lack the sufficient detail and contextual information required for meaningful Aspect-Based Sentiment Analysis.\n",
    "- Choosing a threshold of 5 is a common and practical heuristic in text analysis, designed to balance data retention with data quality.\n",
    "\n",
    "#### Rationale\n",
    "The primary goal is to filter out extremely low-effort, \"zero-context\" reviews. Phrases like:\n",
    "- \"nice comfortable\" (2 words)\n",
    "- \"A satisfying trip\" (3 words)\n",
    "- \"It was so good\" (4 words)\n",
    "\n",
    "While these provide an overall sentiment, they are not meaningful for Aspect-Based Sentiment Analysis because they don't mention what was great or horrible.\n",
    "\n",
    "At the same time, the threshold needs to be low enough to keep short but valuable reviews that do contain a clear aspect and sentiment, such as:\n",
    "- \"Very good service and convenient transportation\" (6 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d6367-a364-4ec8-b86d-772bd9b32543",
   "metadata": {
    "id": "ea7d6367-a364-4ec8-b86d-772bd9b32543",
    "outputId": "59a27672-aee6-4514-9604-a86671840a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original row count: 27392\n",
      "Row count after filtering out short reviews: 17255\n",
      "Number of reviews excluded: 10137\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'word_count'\n",
    "# This splits the review text by spaces, creating a list of words, and then counts the length of that list.\n",
    "df = df.with_columns(\n",
    "    pl.col(\"review_text\").str.split(\" \").list.len().alias(\"word_count\")\n",
    ")\n",
    "\n",
    "# Filter the DataFrame to keep only rows where word_count is greater than 5\n",
    "filtered_df = df.filter(\n",
    "    pl.col(\"word_count\") > 5\n",
    ")\n",
    "\n",
    "print(f\"\\nOriginal row count: {len(df)}\")\n",
    "print(f\"Row count after filtering out short reviews: {len(filtered_df)}\")\n",
    "print(f\"Number of reviews excluded: {len(df) - len(filtered_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2db803-6213-45e7-ac3b-7522f0706fe6",
   "metadata": {
    "id": "ea2db803-6213-45e7-ac3b-7522f0706fe6"
   },
   "source": [
    "#### Experiment 1: Single Step Pipeline for Sentiment Analysis\n",
    "- We are using a deberta-v3-base-absa model, which is specifically trained to take a sentence and an aspect, and then determine the sentiment of that aspect within the sentence. This is much more accurate than a general sentiment model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5fd2e0-554a-441b-a9b7-934bf45c1747",
   "metadata": {
    "id": "7d5fd2e0-554a-441b-a9b7-934bf45c1747"
   },
   "outputs": [],
   "source": [
    "# classifier = pipeline(\"text-classification\", model=\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "# sentence = \"The food was exceptional, although the service was a bit slow.\"\n",
    "# result_food = classifier(sentence, text_pair=\"food\")\n",
    "# print(result_food)\n",
    "\n",
    "# [{'label': 'Positive', 'score': 0.9969689249992371}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62295b53-2d85-49f4-8e4a-fec9d5b43609",
   "metadata": {
    "id": "62295b53-2d85-49f4-8e4a-fec9d5b43609",
    "outputId": "116df760-8c20-4152-a91b-f9f6603892e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading ABSA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSA model loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- LOAD MODEL ---\n",
    "\n",
    "print(\"\\nLoading ABSA model...\")\n",
    "absa_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"yangheng/deberta-v3-base-absa-v1.1\"\n",
    ")\n",
    "print(\"ABSA model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8159c84-778a-4828-b831-9b97c395b3e5",
   "metadata": {
    "id": "e8159c84-778a-4828-b831-9b97c395b3e5",
    "outputId": "b3c87c72-1571-46ed-a8c0-f242b3d9c3ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing a sample of 100 reviews...\n",
      "ABSA processing complete.\n"
     ]
    }
   ],
   "source": [
    "# --- RUN THE ABSA PIPELINE ---\n",
    "\n",
    "# For development, run on a small sample.\n",
    "# To run on the full filtered dataset, change this to: sample_df = filtered_df\n",
    "sample_df = filtered_df.sample(n=100, seed=1)\n",
    "print(f\"\\nProcessing a sample of {len(sample_df)} reviews...\")\n",
    "\n",
    "results = []\n",
    "# Iterate through each review in our sample\n",
    "for row in sample_df.iter_rows(named=True):\n",
    "    review_id = row['review_id']\n",
    "    review_text = row['review_text']\n",
    "\n",
    "    if not review_text:\n",
    "        continue\n",
    "\n",
    "    for aspect in ASPECTS:\n",
    "        input_text = f\"[CLS] {review_text} [SEP] {aspect} [SEP]\"\n",
    "        prediction = absa_classifier(input_text)[0]\n",
    "\n",
    "        # Capture both the sentiment label and the probability score\n",
    "        sentiment = prediction['label'].capitalize()\n",
    "        score = prediction['score']\n",
    "\n",
    "        results.append({\n",
    "            \"review_id\": review_id,\n",
    "            \"aspect\": aspect,\n",
    "            \"sentiment\": sentiment,\n",
    "            \"score\": score  # Add score to our results\n",
    "        })\n",
    "\n",
    "print(\"ABSA processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02512a-3a8d-4269-aee5-63849ce8c427",
   "metadata": {
    "id": "0d02512a-3a8d-4269-aee5-63849ce8c427",
    "outputId": "40f83c23-05a3-466a-e438-62ee5d2a3b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting long-format data for verification...\n",
      "Exported verification file to: output/absa_onestep_results_long_verification.csv\n"
     ]
    }
   ],
   "source": [
    "# --- EXPORT LONG-FORMAT DATA FOR VERIFICATION ---\n",
    "\n",
    "print(\"\\nExporting long-format data for verification...\")\n",
    "# Create the initial long-format DataFrame from the results\n",
    "long_format_df = pl.DataFrame(results)\n",
    "\n",
    "# Join with the original DataFrame to include the review text for context\n",
    "long_verification_df = long_format_df.join(df, on=\"review_id\", how=\"left\")\n",
    "\n",
    "# Export the long-format verification file\n",
    "verification_output_path = \"output/absa_onestep_results_long_verification.csv\"\n",
    "long_verification_df.write_csv(verification_output_path, include_bom=True)\n",
    "print(f\"Exported verification file to: {verification_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f990a7-9636-41ca-be61-1ccaeb10baef",
   "metadata": {
    "id": "06f990a7-9636-41ca-be61-1ccaeb10baef",
    "outputId": "989003a4-7ad9-4731-b9e3-ae4ecb306c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivoting data to wide format...\n",
      "Pivoting complete.\n"
     ]
    }
   ],
   "source": [
    "# --- PIVOT FROM LONG TO WIDE FORMAT ---\n",
    "\n",
    "print(\"\\nPivoting data to wide format...\")\n",
    "# Use the .pivot() method to transform the data\n",
    "# - index: The column that will become the unique row identifier.\n",
    "# - columns: The column whose values will become the new column names.\n",
    "# - values: The columns whose data will fill the new pivoted columns.\n",
    "wide_format_df = long_format_df.pivot(\n",
    "    index=\"review_id\",\n",
    "    columns=\"aspect\",\n",
    "    values=[\"sentiment\", \"score\"]\n",
    ")\n",
    "\n",
    "# The pivot creates columns like 'sentiment_Room Quality & Comfort'.\n",
    "# We will rename them to a cleaner format like 'Room Quality & Comfort_sentiment'.\n",
    "rename_mapping = {}\n",
    "for aspect in ASPECTS:\n",
    "    rename_mapping[f'sentiment_{aspect}'] = f'{aspect}_sentiment'\n",
    "    rename_mapping[f'score_{aspect}'] = f'{aspect}_score'\n",
    "\n",
    "wide_format_df = wide_format_df.rename(rename_mapping)\n",
    "\n",
    "print(\"Pivoting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb2803-8e86-4203-8e21-5d75e1cc6d33",
   "metadata": {
    "id": "a7eb2803-8e86-4203-8e21-5d75e1cc6d33",
    "outputId": "99e1a850-934b-4ceb-ec3e-8c0a44a54a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully exported the final wide-format results to: output/absa_analysis_onestep_results_wide.csv\n"
     ]
    }
   ],
   "source": [
    "# --- JOIN AND EXPORT FINAL WIDE DATAFRAME ---\n",
    "\n",
    "# Join the new wide-format results back to the ORIGINAL full DataFrame.\n",
    "# A 'left' join ensures we keep all original reviews, even those not processed by ABSA.\n",
    "final_analysis_df = df.join(wide_format_df, on=\"review_id\", how=\"left\")\n",
    "\n",
    "# Export the final combined DataFrame\n",
    "output_path = \"output/absa_analysis_onestep_results_wide.csv\"\n",
    "final_analysis_df.write_csv(output_path, include_bom=True)\n",
    "\n",
    "print(f\"\\nSuccessfully exported the final wide-format results to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7674b-3a55-4bf5-81ee-8677fd1381f8",
   "metadata": {
    "id": "ead7674b-3a55-4bf5-81ee-8677fd1381f8"
   },
   "source": [
    "#### Experiment 2: Two Step Pipeline for Sentiment Analysis\n",
    "- Initial methodology for Aspect-Based Sentiment Analysis (ABSA) involved applying a single, specialised model, yangheng/deberta-v3-base-absa-v1.1, to each review for every one of the nine predefined aspects. However, this single-step approach revealed a significant limitation: it was prone to generating spurious sentiment attributions by assigning a score for an aspect even when the review text was not relevant to it.\n",
    "- For instance, the review \"Amazing time , very clean and friendly staff\" received a positve score for the \"Casino Experience.\" This not only introduced noise into the results but was also computationally inefficient, as it required running a resource-intensive model unnecessarily.\n",
    "- To address these limitations, a more sophisticated two-step pipeline was implemented:\n",
    "   1. A high-speed, zero-shot classification model, facebook/bart-large-mnli, performs a relevance check to identify which, if any, aspects are actually discussed in a review.\n",
    "   2. Only if an aspect’s relevance score from this initial check surpasses a predefined confidence threshold of 80% is the review then passed to the specialised yangheng/deberta-v3-base-absa-v1.1 model for fine-grained sentiment analysis.\n",
    "- This conditional, two-step approach ensures that sentiment is only evaluated where contextually relevant, thereby improving the accuracy of the insights and significantly reducing the computational load of the pipeline.\n",
    "\n",
    "====\n",
    "\n",
    "The models for the two-step pipeline were selected for their distinct and complementary strengths:\n",
    "\n",
    "- For the initial relevance check, the facebook/bart-large-mnli model was chosen. This model is a powerful zero-shot classifier trained on Natural Language Inference (NLI), making it exceptionally adept at rapidly determining the topic of a text against a list of custom labels (the aspects) in a single forward pass. Its primary role is to serve as a fast and efficient filter.\n",
    "- For example, given the review \"The pool was amazing, but the check-in queue was a nightmare,\" this model efficiently determines that the most relevant aspects are 'Facilities & Amenities' and 'Customer Service & Staff', while assigning a near-zero relevance score to 'Casino Experience'.\n",
    "\n",
    "- For the subsequent sentiment analysis, the specialised yangheng/deberta-v3-base-absa-v1.1 model was used. This model has been specifically fine-tuned on ABSA datasets, making it an expert at pinpointing the sentiment directed towards a specific target within a sentence. Its role is that of a precise but computationally expensive analyst.\n",
    "- Continuing the example, this model is called twice: first, with the aspect 'Facilities & Amenities', it focuses on the phrase \"The pool was amazing\" to return a Positive sentiment. Second, with 'Customer Service & Staff', it hones in on \"the check-in queue was a nightmare\" to return a Negative sentiment, correctly distinguishing the two conflicting opinions.\n",
    "\n",
    "Source:\n",
    "1. https://huggingface.co/facebook/bart-large-mnli\n",
    "2. https://huggingface.co/yangheng/deberta-v3-base-absa-v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05451c29-624c-4a42-9b1d-30cd152dbf80",
   "metadata": {
    "id": "05451c29-624c-4a42-9b1d-30cd152dbf80"
   },
   "outputs": [],
   "source": [
    "# # https://huggingface.co/facebook/bart-large-mnli\n",
    "\n",
    "# from transformers import pipeline\n",
    "# classifier = pipeline(\"zero-shot-classification\",\n",
    "#                       model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# sequence_to_classify = \"one day I will see the world\"\n",
    "# candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "# classifier(sequence_to_classify, candidate_labels)\n",
    "\n",
    "# #{'labels': ['travel', 'dancing', 'cooking'],\n",
    "# # 'scores': [0.9938651323318481, 0.0032737774308770895, 0.002861034357920289],\n",
    "# # 'sequence': 'one day I will see the world'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b77facd-41ad-4603-a467-1147c486aeac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7822,
     "status": "ok",
     "timestamp": 1759645123068,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "2b77facd-41ad-4603-a467-1147c486aeac",
    "outputId": "882777ef-90cd-4f8f-a1e6-d3aded6adbbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading models (this may take a few minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded.\n"
     ]
    }
   ],
   "source": [
    "# TWO STEP PROCESSING\n",
    "\n",
    "# --- LOAD MODELS ---\n",
    "print(\"\\nLoading models (this may take a few minutes)...\")\n",
    "# Model 1: Fast Zero-Shot classifier for Relevance Identification\n",
    "relevance_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "# Model 2: Specialized ABSA classifier for Sentiment Analysis\n",
    "sentiment_classifier = pipeline(\"text-classification\", model=\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "print(\"Models loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a22da80-ec95-4c11-b017-9958f5da22d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5437918,
     "status": "ok",
     "timestamp": 1759650994013,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "6a22da80-ec95-4c11-b017-9958f5da22d1",
    "outputId": "4aeec538-b7f2-4cf7-d430-bd45ace766d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 27392 reviews in batches of 500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 55/55 [1:30:37<00:00, 98.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSA processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- RUN THE ABSA PIPELINE (IN BATCHES TO PREVENT CRASHES) ---\n",
    "\n",
    "# Define the size of each batch\n",
    "BATCH_SIZE = 500  # You can adjust this if needed\n",
    "\n",
    "# Use pandas to read the CSV in chunks for memory-efficient processing\n",
    "try:\n",
    "    # We use Polars to quickly scan the file and get an accurate count.\n",
    "    total_rows = pl.scan_csv(FILE_PATH).collect().height\n",
    "\n",
    "    # Now, read the file in chunks with pandas for the batch processing loop.\n",
    "    csv_chunks = pd.read_csv(FILE_PATH, chunksize=BATCH_SIZE)\n",
    "\n",
    "    print(f\"\\nProcessing {total_rows} reviews in batches of {BATCH_SIZE}...\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at path: {FILE_PATH}\")\n",
    "    print(\"Please make sure the path is correct and your Google Drive is mounted.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "results = []\n",
    "row_offset = 0 # Initialize a counter to create a continuous review_id\n",
    "# Wrap the csv_chunks iterator with tqdm for a progress bar\n",
    "for batch_pd in tqdm(csv_chunks, total=-(total_rows // -BATCH_SIZE), desc=\"Processing Batches\"):\n",
    "\n",
    "    # Manually add a continuous review_id to each batch\n",
    "    batch_pd['review_id'] = range(row_offset, row_offset + len(batch_pd))\n",
    "    row_offset += len(batch_pd)\n",
    "\n",
    "    # Convert the pandas batch to a Polars DataFrame for processing\n",
    "    batch_pl = pl.from_pandas(batch_pd)\n",
    "\n",
    "    # Calculate word count for the current batch\n",
    "    batch_pl = batch_pl.with_columns(\n",
    "        pl.col(\"review_text\").str.split(\" \").list.len().alias(\"word_count\")\n",
    "    )\n",
    "\n",
    "    # Iterate through each review in the current batch\n",
    "    for row in batch_pl.iter_rows(named=True):\n",
    "\n",
    "        # We only process reviews with more than 5 words\n",
    "        if not row['review_text'] or row['word_count'] <= 5:\n",
    "            continue\n",
    "\n",
    "        review_id = row['review_id']\n",
    "        review_text = row['review_text']\n",
    "\n",
    "        try:\n",
    "            # --- STEP 1: RELEVANCE IDENTIFICATION ---\n",
    "            relevance_prediction = relevance_classifier(review_text, candidate_labels=ASPECTS, multi_label=True)\n",
    "\n",
    "            for aspect, relevance_score in zip(relevance_prediction['labels'], relevance_prediction['scores']):\n",
    "                # --- STEP 2: CONDITIONAL SENTIMENT ANALYSIS ---\n",
    "                if relevance_score > 0.80:\n",
    "                    input_text = f\"[CLS] {review_text} [SEP] {aspect} [SEP]\"\n",
    "                    sentiment_prediction = sentiment_classifier(input_text)[0]\n",
    "\n",
    "                    results.append({\n",
    "                        \"review_id\": review_id, \"aspect\": aspect, \"relevance_score\": relevance_score,\n",
    "                        \"sentiment\": sentiment_prediction['label'].capitalize(),\n",
    "                        \"sentiment_score\": sentiment_prediction['score']\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            # This catch block will handle any errors during the model inference for a single review\n",
    "            print(f\"Skipping review {review_id} due to an error: {e}\")\n",
    "\n",
    "print(\"ABSA processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "033e3c98-8ea1-4728-b025-07f3d15b096a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1759651240953,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "033e3c98-8ea1-4728-b025-07f3d15b096a",
    "outputId": "98548d11-6a37-485d-eef7-68692db0d4a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating word count for the full dataset...\n",
      "Pivoting data to wide format for dashboard...\n",
      "Pivoting complete.\n",
      "\n",
      "Successfully exported the final wide-format results to: /content/drive/MyDrive/CI/output/absa_analysis_twostep_results_wide.csv\n"
     ]
    }
   ],
   "source": [
    "# --- CREATE FINAL DATAFRAME ---\n",
    "if results:\n",
    "    # Create the long-format DataFrame from the results list.\n",
    "    long_format_df = pl.DataFrame(results)\n",
    "\n",
    "    # Load the original full DataFrame again. We will add the word_count\n",
    "    # to this DataFrame before joining.\n",
    "    full_df = pl.read_csv(FILE_PATH)\n",
    "    if \"review_id\" not in full_df.columns:\n",
    "        full_df = full_df.with_row_index(name=\"review_id\")\n",
    "\n",
    "    # This ensures the 'word_count' column will be in the final exported CSV.\n",
    "    print(\"\\nCalculating word count for the full dataset...\")\n",
    "    full_df = full_df.with_columns(\n",
    "        pl.col(\"review_text\").str.split(\" \").list.len().alias(\"word_count\")\n",
    "    )\n",
    "\n",
    "    # Pivot the long-format results into a wide format for the dashboard.\n",
    "    print(\"Pivoting data to wide format for dashboard...\")\n",
    "    wide_format_df = long_format_df.pivot(\n",
    "        index=\"review_id\",\n",
    "        columns=\"aspect\",\n",
    "        values=[\"sentiment\", \"sentiment_score\", \"relevance_score\"]\n",
    "    )\n",
    "    rename_mapping = {}\n",
    "    for aspect in ASPECTS:\n",
    "        if f'sentiment_{aspect}' in wide_format_df.columns: # Check if column exists before renaming\n",
    "            rename_mapping[f'sentiment_{aspect}'] = f'{aspect}_sentiment'\n",
    "            rename_mapping[f'sentiment_score_{aspect}'] = f'{aspect}_sentiment_score'\n",
    "            rename_mapping[f'relevance_score_{aspect}'] = f'{aspect}_relevance_score'\n",
    "    wide_format_df = wide_format_df.rename(rename_mapping)\n",
    "    print(\"Pivoting complete.\")\n",
    "\n",
    "    # Join the wide results back to the full original DataFrame (which now has word_count).\n",
    "    final_analysis_df = full_df.join(wide_format_df, on=\"review_id\", how=\"left\")\n",
    "\n",
    "    # Create the output directory if it doesn't exist.\n",
    "    output_dir = \"/content/drive/MyDrive/CI/output\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Export the final wide-format DataFrame.\n",
    "    output_path = os.path.join(output_dir, \"absa_analysis_twostep_results_wide.csv\")\n",
    "    final_analysis_df.write_csv(output_path, include_bom=True)\n",
    "    print(f\"\\nSuccessfully exported the final wide-format results to: {output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo results were generated. This could be due to the sample size or relevance threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06de1442-2320-499f-9aaa-09a219e6f8e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1759651612576,
     "user": {
      "displayName": "Jason Khoo",
      "userId": "02337239789487895345"
     },
     "user_tz": -480
    },
    "id": "06de1442-2320-499f-9aaa-09a219e6f8e5",
    "outputId": "955eeb4e-638a-498f-9478-e52f89481c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported the final results to Parquet: /content/drive/MyDrive/CI/output/absa_analysis_twostep_results_wide.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Export the same DataFrame to Parquet for efficient storage and faster loading\n",
    "parquet_output_path = os.path.join(output_dir, \"absa_analysis_twostep_results_wide.parquet\")\n",
    "final_analysis_df.write_parquet(parquet_output_path)\n",
    "print(f\"Successfully exported the final results to Parquet: {parquet_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DNBZoObWZ4Nv",
   "metadata": {
    "id": "DNBZoObWZ4Nv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
